
# 可计算的 Content Network (Computable Content Network)

**—— 基于 BuckyOS 的去中心化信息基础设施新范式**

## 摘要 (Abstract)

传统的互联网内容分发网络（CDN）本质上是静态数据的缓存与路由系统。随着生成式 AI 的崛起，内容正从“预存储的静态文件”转向“即时生成的计算结果”。本文提出了一种全新的“可计算 Content Network”架构，通过引入**基于算子的引用（Operator-based Referencing）**、**流式算子（Streaming Operators）**以及**亲和性感知调度（Affinity-Aware Scheduling）**，将计算过程与内容寻址深度耦合。该架构不仅保障了内容创作者的权利，更通过 **Lazy Evaluation（惰性求值）** 机制实现了全球规模的分布式计算协同。

## 1. 核心哲学：内容即计算结果

在可计算 Content Network 中，一个内容的标识符（URL）不再仅指向物理存储中的二进制序列，而是指向一个**确定性的计算过程**。

* **公式定义**：
* 任何被引用的对象（NamedObject）都可以作为算子的输入，而算子的输出又自动成为网络中的新内容节点，形成了递归嵌套的价值链条。

## 2. 核心组件与机制

### 2.1 BaseContentObject：角色的解耦与确权

为了实现公平透明的传播规则，我们将内容的网络属性定义为四种核心角色的解耦：

* **Author/Owner**：定义版权与利益原点。
* **Indexer (收录者)**：去中心化的策展人，通过单/双向收录证明其价值。
* **Distributor (传播者)**：基于 Context（如社交分享）的流动路径。
* **Consumer (消费者)**：利益的起点，其行为轨迹通过 ZK 技术转化为被动评级。

### 2.2 延迟寻址与惰性求值 (Lazy Evaluation)

系统支持 `result_url = calc_obj(op, inputs)` 的声明式表达。计算不会在定义时发生，而是在用户发起 `read` 请求时，由调度器反向追溯计算图（DAG）。这极大减少了无效的中间结果存储，实现了存储空间的“按需物化”。

### 2.3 可迭代的流式算子 (Streaming & Seekable Operators)

针对大规模 AI 训练（如 LLM），传统的块计算被拆解为可迭代的流（Stream）。

* **可 Seek 性**：支持从计算流的任意 Offset（如 Transformer 的特定层级）开始推进。
* **容错性**：当算力节点失效，系统可自动寻址到最近的状态快照并 Seek 恢复，实现无感知的弹性计算。

## 3. 调度哲学：亲和性感知 (Affinity-Awareness)

由于数据规模与计算规模的非对称性，调度器根据算子属性执行差异化策略：

* **Source 亲和**：适用于数据密集型任务（如 Tokenization）。算子向数据端移动，实现“零搬运”预处理。
* **Result 亲和**：适用于计算密集型任务（如 Forward/Backward）。数据与模型向高性能算力集群汇聚，通过 RDMA 拓扑实现极致吞吐。

## 4. 经济模型：基于名字的利益锚点

BuckyOS 的经济模型围绕 `Name` 展开。

* **利益原点**：用户消费行为触发利益分配算法，根据计算链条自动反向回溯，为作者、收录者、分享者乃至提供算子的节点分配分红。
* **消费证明 (Use-to-Earn)**：通过行为交叉验证与信用种子节点，构建抗机器人的真实信用系统。

## 5. 结论与愿景

“可计算 Content Network”不仅是一次技术重构，更是一次生产关系的革新。它将互联网从“平台围墙花园”转型为“流动的语义与计算网”。在 AI 时代，这种架构为人类提供了一个即便公开规则也难以被机器“刷信用”的信任底座，保障了高质量内容在噪音时代的生存空间。



对于《可计算 Content Network》而言，调度器（Scheduler）不再是简单的任务分配器，而是一个**“成本-路径优化引擎”**。它的核心任务是在全局名字空间中，寻找执行 `calc_obj` 的最优物理位置。

以下是 BuckyOS 调度器在计算场景下的核心实现逻辑：

---

## BuckyOS 调度器：计算生命周期管理

### 1. 逻辑拓扑解析 (Graph Construction)

当用户调用 `open_reader(result_url)` 时，调度器首先进入**递归解析阶段**。

* **依赖展开**：从 `result_url` 开始，向上回溯所有的输入（Input URLs）。如果输入本身也是一个 `calc_obj`，则继续展开，直到触达原始数据（Raw Data）或已物化的缓存（Materialized Cache）。
* **算子识别**：识别算子的元数据（Metadata），包括它是否支持 **Stream**、**Seek**，以及作者定义的**亲和性倾向**。

### 2. 亲和性博弈与选址 (Affinity-Based Placement)

这是调度器的精华所在。它通过一个评分函数（Scoring Function）来决定算子落在哪个 Node 上：

#### A. Source 亲和 (Data-Centric)

* **场景**：清洗、过滤、特征提取。
* **策略**：计算向数据移动。调度器优先选择存储了 `urlA` 的 OOD 节点。
* **优势**：极大节省全球网络带宽，处理“TB 级原始数据 -> GB 级中间结果”的场景。

#### B. Result 亲和 (Compute-Centric)

* **场景**：模型训练、推理、渲染。
* **策略**：数据向计算移动。调度器优先选择拥有特定硬件（如 H100, TPU）且网络延迟最低的节点。
* **物化决策**：如果多个用户同时请求同一个计算结果，调度器会选定一个核心节点进行“计算物化”，其他用户则变为“流订阅者”。

---

### 3. 流式执行与背压控制 (Streaming Execution & Backpressure)

对于你提到的 **Stream 算子**，调度器采用“生产者-消费者”模型：

* **按需拉取**：只有当下游 `read` 了特定的 Offset，上游算子才会被激活。
* **动态 Seek**：如果 `reader` 突然跳转到 Layer 80，调度器会立即向执行节点发送 `SEEK` 指令。如果当前节点没有缓存之前的状态，调度器会启动**“并行回溯”**，寻找存储了最近快照（Checkpoint）的节点进行状态恢复。

### 4. 弹性容错与“重调度” (Rescheduling)

由于计算发生在不稳定的 Personal Zone（OOD）之间，掉线是常态。

* **心跳监控**：调度器实时监控执行节点的健康度。
* **无感转移**：一旦节点 A 掉线，调度器根据 `calc_obj` 的确定性属性，在节点 B 重新启动任务。由于算子是 **Seekable** 的，调度器会指挥节点 B 从最近的一个 `NamedObject` 快照点开始恢复计算流。

---

## 调度器内部逻辑流程 (Scheduler Workflow)

1. **Request**: 接收到 `read(Object_ID)`。
2. **Match**: 检查本地及网络 Cache。命中则直接返回，未命中进入 **Calc Mode**。
3. **Analyze**: 拆解 DAG，标记 `Source-Affinity` 节点和 `Result-Affinity` 节点。
4. **Contract**: 向目标节点发起“计算契约（Computing Contract）”请求，确认资源（显存、带宽）可用性。
5. **Execute**: 下发算子闭包（Operator Closure）至目标节点。
6. **Stream**: 建立 P2P 数据通道，将计算结果以流形式回传。
7. **Settle**: 计算完成后，根据经济模型触发利益结算（分红给算力提供者和内容所有者）。

---

## 给 AI 算法工程师的总结


> “在 BuckyOS 里，你不是在给服务器下指令，你是在给**结果**下定义。调度器就像一个自动化的 DevOps 团队，它根据你定义的亲和性，在全网帮你寻找最便宜、最快、离数据最近的显卡。如果中间有人拔了电源，调度器会自动换一台机器，并从上一个层级（Seekable Layer）帮你接上。”
